# ==================================================================
# model.gin
# --------------------------------------------
# model
import bpnet
import bpnet.models
import bpnet.heads
import bpnet.layers
import bpnet.seqmodel
import bpnet.trainers
import bpnet.losses
import bpnet.datasets
import bpnet.metrics

# SeqModel
train.model = @bpnet_model()
bpnet_model.tasks = %tasks
bpnet_model.filters = %filters
bpnet_model.seqlen = %seq_width

bpnet_model.n_dil_layers = %n_dil_layers
bpnet_model.conv1_kernel_size = 25
bpnet_model.tconv_kernel_size = %tconv_kernel_size
bpnet_model.batchnorm = %batchnorm
bpnet_model.lr = %lr
bpnet_model.padding = 'same'
bpnet_model.use_bias = %use_bias
bpnet_model.n_bias_tracks = %n_bias_tracks
bpnet_model.profile_bias_window_sizes = [1, 50]

# specified from the CLI
bpnet_model.b_loss_weight = 0
bpnet_model.c_loss_weight = %lambda
bpnet_model.p_loss_weight = 1
bpnet_model.merge_profile_reg = False

# default profile evaluation metric
bpnet_model.profile_metric = @PeakPredictionProfileMetric()
PeakPredictionProfileMetric.pos_min_threshold = 0.015
PeakPredictionProfileMetric.neg_max_threshold = 0.005
PeakPredictionProfileMetric.required_min_pos_counts = 2.5
binsizes = [1, 10]

# --------------------------------------------
# training
train.seed = None
train.batch_size = 128
train.epochs = 200
train.early_stop_patience = 5
train.num_workers = 6

# --------------------------------------------
# data
# TODO - shall we try to avoid macros as much as possible?

# seq_width  -> specified from gin-bindings
train.data = @bpnet_data()
bpnet_data.peak_width = %seq_width
bpnet_data.valid_chr = %valid_chr
bpnet_data.test_chr = %test_chr
bpnet_data.include_metadata = False
bpnet_data.tasks = %tasks
bpnet_data.exclude_chr = %exclude_chr
bpnet_data.augment_interval = %augment_interval
bpnet_data.interval_augmentation_shift = 200

# transform the bias track by aggregating it in a
# sliding window fashion with window sizes of 1 bp (no aggregation) and 50 bp

# TODO - move that into the model -> apply two convolutional layers with constant width

# specified from the CLI
bpnet_data.dataspec = %dataspec
bpnet_data.seq_width = %seq_width
train.train_epoch_frac = 1.0
train.valid_epoch_frac = 1.0

train.eval_report = @report_template()
report_template.name = 'evaluate.ipynb'

# ============================================
# Macros 
augment_interval = True

lambda = 10  # count loss weight 
filters = 64
tconv_kernel_size = 25
lr = 0.004
n_dil_layers = 9
train.batch_size = 128
batchnorm = False
seq_width = 1000
# TODO - mention the usage of macros

# TODO - important parameters you might want to adjust
valid_chr = ['chr2', 'chr3', 'chr4']
test_chr = ['chr1', 'chr8', 'chr9']
exclude_chr = ['chrX', 'chrY']
# ============================================
# These parameters will be specified from the command line
# (i.e. in `bpnet.cli.train.bpnet_train` function)

# use_bias = True  # set to False if you would like to not use the bias in the model
# n_bias_tracks = 2
# dataspec = 'ChIP-nexus.dataspec.yml'
# tasks = ['Oct4', 'Sox2', 'Nanog', 'Klf4']
