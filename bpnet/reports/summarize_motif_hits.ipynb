{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to results\n",
    "[Proportion of peaks with hits](#peaks-with-hits)\n",
    "\n",
    "[Examples of motif hits](#example-hits)\n",
    "\n",
    "[Homotypic density of motifs in peaks](#density)\n",
    "\n",
    "[Co-occurrence of motifs in peaks](#co-occurrence)\n",
    "\n",
    "[Distance between co-occurring motifs](#distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reset -f\n",
    "import os\n",
    "import util\n",
    "import moods\n",
    "import h5py\n",
    "import viz_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pomegranate\n",
    "import sklearn.cluster\n",
    "import scipy.cluster.hierarchy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import subprocess\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "tfm_results_path = os.environ[\"TFM_TFM_PATH\"]\n",
    "shap_scores_path = os.environ[\"TFM_SHAP_PATH\"]\n",
    "peak_bed_paths = [os.environ[\"TFM_PEAKS_PATH\"]]\n",
    "moods_dir = os.environ[\"TFM_MOODS_DIR\"]\n",
    "reference_fasta = os.environ[\"TFM_REFERENCE_PATH\"]\n",
    "\n",
    "print(\"TF-MoDISco results path: %s\" % tfm_results_path)\n",
    "print(\"DeepSHAP scores path: %s\" % shap_scores_path)\n",
    "print(\"Peaks path: %s\" % peak_bed_paths[0])\n",
    "print(\"MOODS directory: %s\" % moods_dir)\n",
    "print(\"Reference genome path: %s\" % reference_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "input_length = 2114\n",
    "hyp_score_key = \"hyp_scores\"\n",
    "motif_fdr_cutoff = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For plotting and organizing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_motifs(tfm_results_path, trim=True, only_pos=True):\n",
    "    \"\"\"\n",
    "    Imports the PFMs to into a dictionary, mapping `(x, y)` to the PFM,\n",
    "    where `x` is the metacluster index and `y` is the pattern index.\n",
    "    Arguments:\n",
    "        `tfm_results_path`: path to HDF5 containing TF-MoDISco results\n",
    "        `out_dir`: where to save motifs\n",
    "        `trim`: if True, trim the motif flanks based on information content\n",
    "        `only_pos`: if True, only return motifs with positive contributions\n",
    "    Returns the dictionary of PFMs.\n",
    "    \"\"\" \n",
    "    pfms = {}\n",
    "    with h5py.File(tfm_results_path, \"r\") as f:\n",
    "        metaclusters = f[\"metacluster_idx_to_submetacluster_results\"]\n",
    "        num_metaclusters = len(metaclusters.keys())\n",
    "        for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "            metacluster = metaclusters[metacluster_key]\n",
    "            if \"patterns\" not in metacluster[\"seqlets_to_patterns_result\"]:\n",
    "                continue\n",
    "            patterns = metacluster[\"seqlets_to_patterns_result\"][\"patterns\"]\n",
    "            num_patterns = len(patterns[\"all_pattern_names\"][:])\n",
    "            for pattern_i, pattern_name in enumerate(patterns[\"all_pattern_names\"][:]):\n",
    "                pattern_name = pattern_name.decode()\n",
    "                pattern = patterns[pattern_name]\n",
    "                pfm = pattern[\"sequence\"][\"fwd\"][:]\n",
    "                cwm = pattern[\"task0_contrib_scores\"][\"fwd\"][:]\n",
    "                \n",
    "                # Check that the contribution scores are overall positive\n",
    "                if only_pos and np.sum(cwm) < 0:\n",
    "                    continue\n",
    "                    \n",
    "                if trim:\n",
    "                    pfm = util.trim_motif(pfm, pfm)\n",
    "                    \n",
    "                pfms[\"%d_%d\" % (metacluster_i,pattern_i)] = pfm\n",
    "    return pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mode(x_values, bins=200, levels=1):\n",
    "    \"\"\"\n",
    "    Estimates the mode of the distribution using `levels`\n",
    "    iterations of histograms.\n",
    "    \"\"\"\n",
    "    hist, edges = np.histogram(x_values, bins=bins)\n",
    "    bin_mode = np.argmax(hist)\n",
    "    left_edge, right_edge = edges[bin_mode], edges[bin_mode + 1]\n",
    "    if levels <= 1:\n",
    "        return (left_edge + right_edge) / 2\n",
    "    else:\n",
    "        return estimate_mode(\n",
    "            x_values[(x_values >= left_edge) & (x_values < right_edge)],\n",
    "            bins=bins,\n",
    "            levels=(levels - 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tight_exponential_dist(x_values, mode=0, percentiles=np.arange(0.05, 1, 0.05)):\n",
    "    \"\"\"\n",
    "    Given an array of x-values and a set of percentiles of the distribution,\n",
    "    computes the set of lambda values for an exponential distribution if the\n",
    "    distribution were fit to each percentile of the x-values. Returns an array\n",
    "    of lambda values parallel to `percentiles`. The exponential distribution\n",
    "    is assumed to have the given mean/mode, and all data less than this mode\n",
    "    is tossed out when doing this computation.\n",
    "    \"\"\"\n",
    "    assert np.min(percentiles) >= 0 and np.max(percentiles) <= 1\n",
    "    x_values = x_values[x_values >= mode]\n",
    "    per_x_vals = np.percentile(x_values, percentiles * 100)\n",
    "    return -np.log(1 - percentiles) / (per_x_vals - mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_pdf(x_values, lamb):\n",
    "    return lamb * np.exp(-lamb * x_values)\n",
    "def exponential_cdf(x_values, lamb):\n",
    "    return 1 - np.exp(-lamb * x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_peak_hits_by_fdr(hit_table, fdr_cutoff=0.05):\n",
    "    \"\"\"\n",
    "    Filters the table of peak hits (as imported by `moods.import_moods_hits`)\n",
    "    by the importance score fraction by fitting a mixture model to the score\n",
    "    distribution, taking the exponential component, and then fitting a\n",
    "    percentile-tightened exponential distribution to this component.\n",
    "    p-values are computed using this null, and then the FDR-cutoff is applied\n",
    "    using Benjamini-Hochberg.\n",
    "    Returns a reduced hit table of the same format. This will also generate\n",
    "    plots for the score distribution and the FDR cutoffs.\n",
    "    \"\"\"\n",
    "    scores = hit_table[\"imp_frac_score\"].values\n",
    "    scores_finite = scores[np.isfinite(scores)]\n",
    "    \n",
    "    mode = estimate_mode(scores_finite)\n",
    "\n",
    "    # Fit mixture of models to scores (mode-shifted)\n",
    "    over_mode_scores = scores_finite[scores_finite >= mode] - mode\n",
    "    mixed_model = pomegranate.GeneralMixtureModel.from_samples(\n",
    "        [\n",
    "            pomegranate.ExponentialDistribution,\n",
    "            pomegranate.NormalDistribution,\n",
    "            pomegranate.NormalDistribution\n",
    "        ],\n",
    "        3, over_mode_scores[:, None]\n",
    "    )\n",
    "    mixed_model = mixed_model.fit(over_mode_scores)\n",
    "    mixed_model_exp_dist = mixed_model.distributions[0]\n",
    "    \n",
    "    # Obtain a distribution of scores that belong to the exponential distribution\n",
    "    exp_scores = over_mode_scores[mixed_model.predict(over_mode_scores[:, None]) == 0]\n",
    "    \n",
    "    # Fit a tight exponential distribution based on percentiles\n",
    "    lamb = np.max(fit_tight_exponential_dist(exp_scores))\n",
    "    \n",
    "    # Plot score distribution and fit\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, figsize=(20, 20))\n",
    "\n",
    "    x = np.linspace(np.min(scores_finite), np.max(scores_finite), 200)[1:]  # Skip first bucket (it's usually very large\n",
    "    mix_dist_pdf = mixed_model.probability(x)\n",
    "    mixed_model_exp_dist_pdf = mixed_model_exp_dist.probability(x)\n",
    "\n",
    "    perc_dist_pdf = exponential_pdf(x, lamb)\n",
    "    perc_dist_cdf = exponential_cdf(x, lamb)\n",
    "\n",
    "    # Plot mixed model\n",
    "    ax[0].hist(over_mode_scores + mode, bins=500, density=True, alpha=0.3)\n",
    "    ax[0].axvline(mode)\n",
    "    ax[0].plot(x + mode, mix_dist_pdf, label=\"Mixed model\")\n",
    "    ax[0].plot(x + mode, mixed_model_exp_dist_pdf, label=\"Exponential component\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Plot fitted PDF\n",
    "    ax[1].hist(exp_scores, bins=500, density=True, alpha=0.3)\n",
    "    ax[1].plot(x + mode, perc_dist_pdf, label=\"Percentile-fitted\")\n",
    "\n",
    "    # Plot fitted CDF\n",
    "    ax[2].hist(exp_scores, bins=500, density=True, alpha=1, cumulative=True, histtype=\"step\")\n",
    "    ax[2].plot(x + mode, perc_dist_cdf, label=\"Percentile-fitted\")\n",
    "\n",
    "    ax[0].set_title(\"Motif hit scores\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute p-values\n",
    "    score_range = np.linspace(np.min(scores_finite), np.max(scores_finite), 1000000)\n",
    "    inverse_cdf = 1 - exponential_cdf(score_range, lamb)\n",
    "    assignments = np.digitize(scores - mode, score_range, right=True)\n",
    "    assignments[~np.isfinite(scores)] = 0  # If score was NaN, give it a p-value of ~1\n",
    "    pvals = inverse_cdf[assignments]\n",
    "    pvals_sorted = np.sort(pvals)\n",
    "\n",
    "    # Plot FDR cut-offs of various levels\n",
    "    fdr_levels = [0.05, 0.1, 0.2, 0.3]\n",
    "    pval_threshes = []\n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    ranks = np.arange(1, len(pvals_sorted) + 1)\n",
    "    ax.plot(ranks, pvals_sorted, color=\"black\", label=\"p-values\")\n",
    "    for fdr in fdr_levels:\n",
    "        bh_crit_vals = ranks / len(ranks) * fdr\n",
    "        ax.plot(ranks, bh_crit_vals, label=(\"Crit values (FDR = %.2f)\" % fdr))\n",
    "        inds = np.where(pvals_sorted <= bh_crit_vals)[0]\n",
    "        if not len(inds):\n",
    "            pval_threshes.append(-1)\n",
    "        else:\n",
    "            pval_threshes.append(pvals_sorted[np.max(inds)])\n",
    "    ax.set_title(\"Step-up p-values and FDR corrective critical values\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show table of number of hits at each FDR level\n",
    "    header = vdomh.thead(\n",
    "        vdomh.tr(\n",
    "            vdomh.th(\"FDR level\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"Number of hits kept\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"% hits kept\", style={\"text-align\": \"center\"})\n",
    "        )\n",
    "    )\n",
    "    rows = []\n",
    "    for i, fdr in enumerate(fdr_levels):\n",
    "        num_kept = np.sum(pvals <= pval_threshes[i])\n",
    "        frac_kept = num_kept / len(pvals)\n",
    "        rows.append(vdomh.tr(\n",
    "            vdomh.td(\"%.2f\" % fdr), vdomh.td(\"%d\" % num_kept), vdomh.td(\"%.2f%%\" % (frac_kept * 100))\n",
    "        ))\n",
    "    body = vdomh.tbody(*rows)\n",
    "    display(vdomh.table(header, body))\n",
    "\n",
    "    # Perform filtering\n",
    "    bh_crit_vals = fdr_cutoff * ranks / len(ranks)\n",
    "    inds = np.where(pvals_sorted <= bh_crit_vals)[0]\n",
    "    if not len(inds):\n",
    "        pval_thresh = -1\n",
    "    else:\n",
    "        pval_thresh = pvals_sorted[np.max(inds)]\n",
    "    return hit_table.iloc[pvals <= pval_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_hits(peak_table, hit_table):\n",
    "    \"\"\"\n",
    "    For each peak, extracts the set of motif hits that fall in that peak.\n",
    "    Returns a list mapping peak index to a subtable of `hit_table`. The index\n",
    "    of the list is the index of the peak table.\n",
    "    \"\"\"\n",
    "    peak_hits = [pd.DataFrame(columns=list(hit_table))] * len(peak_table)\n",
    "    for peak_index, matches in tqdm.notebook.tqdm(hit_table.groupby(\"peak_index\")):\n",
    "        # Check that all of the matches are indeed overlapping the peak\n",
    "        peak_row = peak_table.iloc[peak_index]\n",
    "        chrom, start, end = peak_row[\"chrom\"], peak_row[\"peak_start\"], peak_row[\"peak_end\"]\n",
    "        assert np.all(matches[\"chrom\"] == chrom)\n",
    "        assert np.all((matches[\"start\"] < end) & (start < matches[\"end\"]))\n",
    "        \n",
    "        peak_hits[peak_index] = matches\n",
    "    return peak_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_motif_counts(peak_hits, motif_keys):\n",
    "    \"\"\"\n",
    "    From the peak hits (as returned by `get_peak_hits`), computes a count\n",
    "    array of size N x M, where N is the number of peaks and M is the number of\n",
    "    motifs. Each entry represents the number of times a motif appears in a peak.\n",
    "    `motif_keys` is a list of motif keys as they appear in `peak_hits`; the\n",
    "    order of the motifs M matches this list.\n",
    "    \"\"\"\n",
    "    motif_inds = {motif_keys[i] : i for i in range(len(motif_keys))}\n",
    "    counts = np.zeros((len(peak_hits), len(motif_keys)), dtype=int)\n",
    "    for i in tqdm.notebook.trange(len(peak_hits)):\n",
    "        hits = peak_hits[i]\n",
    "        for key, num in zip(*np.unique(hits[\"key\"], return_counts=True)):\n",
    "            counts[i][motif_inds[key]] = num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_matrix_indices(matrix, num_clusters):\n",
    "    \"\"\"\n",
    "    Clusters matrix using k-means. Always clusters on the first\n",
    "    axis. Returns the indices needed to optimally order the matrix\n",
    "    by clusters.\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        # Don't cluster at all\n",
    "        return np.array([0])\n",
    "\n",
    "    num_clusters = min(num_clusters, len(matrix))\n",
    "    \n",
    "    # Perform k-means clustering\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=num_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(matrix)\n",
    "\n",
    "    # Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "            scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Order the peaks so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "    return cluster_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak_motif_indicator_heatmap(peak_hit_counts, motif_keys):\n",
    "    \"\"\"\n",
    "    Plots a simple indicator heatmap of the motifs in each peak.\n",
    "    \"\"\"\n",
    "    peak_hit_indicators = (peak_hit_counts > 0).astype(int)\n",
    "    # Cluster matrix by peaks\n",
    "    inds = cluster_matrix_indices(peak_hit_indicators, max(5, len(peak_hit_indicators) // 10))\n",
    "    matrix = peak_hit_indicators[inds]\n",
    "    \n",
    "    # Cluster matrix by motifs\n",
    "    matrix_t = np.transpose(matrix)\n",
    "    inds = cluster_matrix_indices(matrix_t, max(5, len(matrix_t) // 4))\n",
    "    matrix = np.transpose(matrix_t[inds])\n",
    "    motif_keys = np.array(motif_keys)[inds]\n",
    "\n",
    "    # Create a figure with the right dimensions\n",
    "    fig_height = min(len(peak_hit_indicators) * 0.004, 8)\n",
    "    fig, ax = plt.subplots(figsize=(16, fig_height))\n",
    "\n",
    "    # Plot the heatmap\n",
    "    ax.imshow(matrix, interpolation=\"nearest\", aspect=\"auto\", cmap=\"Greens\")\n",
    "\n",
    "    # Set axes on heatmap\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(np.arange(len(motif_keys)))\n",
    "    ax.set_xticklabels(motif_keys)\n",
    "    ax.set_xlabel(\"Motif\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_homotypic_densities(peak_hit_counts, motif_keys):\n",
    "    \"\"\"\n",
    "    Plots a CDF of number of motif hits per peak, for each motif.\n",
    "    \"\"\"\n",
    "    for i in range(len(motif_keys)):\n",
    "        counts = peak_hit_counts[:, i]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        bins = np.concatenate([np.arange(np.max(counts)), [np.inf]])\n",
    "        ax.hist(counts, bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "        ax.set_title(\"Cumulative distribution of number of %s hits per peak\" % motif_keys[i])\n",
    "        ax.set_xlabel(\"Number of motifs k in peak\")\n",
    "        ax.set_ylabel(\"Proportion of peaks with at least k motifs\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif_cooccurrence_count_matrix(peak_hit_counts):\n",
    "    \"\"\"\n",
    "    From an N x M (peaks by motifs) array of hit counts, returns\n",
    "    an M x M array of counts (i.e. how many times two motifs occur\n",
    "    together in the same peak). For the diagonal entries, we require\n",
    "    that motif occur at least twice in a peak to be counted.\n",
    "    \"\"\"\n",
    "    peak_hit_indicators = (peak_hit_counts > 0).astype(int)\n",
    "    num_motifs = peak_hit_indicators.shape[1]\n",
    "    count_matrix = np.zeros((num_motifs, num_motifs), dtype=int)\n",
    "    for i in range(num_motifs):\n",
    "        for j in range(i):\n",
    "            pair_col = np.sum(peak_hit_indicators[:, [i, j]], axis=1)\n",
    "            count = np.sum(pair_col == 2)\n",
    "            count_matrix[i, j] = count\n",
    "            count_matrix[j, i] = count\n",
    "        count_matrix[i, i] = np.sum(peak_hit_counts[:, i] >= 2)\n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cooccurrence_pvals(peak_hit_counts):\n",
    "    \"\"\"\n",
    "    Given the number of motif hits in each peak, computes p-value of\n",
    "    co-occurrence for each pair of motifs, including self pairs.\n",
    "    Returns an M x M array of p-values for the M motifs.\n",
    "    \"\"\"\n",
    "    peak_hit_indicators = (peak_hit_counts > 0).astype(int)\n",
    "    num_peaks, num_motifs = peak_hit_counts.shape\n",
    "    \n",
    "    pvals = np.ones((num_motifs, num_motifs))\n",
    "    \n",
    "    # Significance is based on a Fisher's exact test. If the motifs were\n",
    "    # present in peaks randomly, we'd independence of occurrence.\n",
    "    # For self-co-occurrence, the null model is not independence, but\n",
    "    # collisions\n",
    "    for i in range(num_motifs):\n",
    "        for j in range(i):\n",
    "            pair_counts = peak_hit_indicators[:, [i, j]]\n",
    "            peaks_with_1 = pair_counts[:, 0] == 1\n",
    "            peaks_with_2 = pair_counts[:, 1] == 1\n",
    "            # Contingency table (universe is set of all peaks):\n",
    "            #              no motif 1  |  has motif 1\n",
    "            # no motif 2       A       |      B\n",
    "            # -------------------------+--------------\n",
    "            # has motif 2      C       |      D\n",
    "            # The Fisher's exact test evaluates the significance of the\n",
    "            # association between the two classifications\n",
    "            cont_table = np.array([\n",
    "                [\n",
    "                    np.sum(~(peaks_with_1) & (~peaks_with_2)),\n",
    "                    np.sum(peaks_with_1 & (~peaks_with_2))\n",
    "                ],\n",
    "                [\n",
    "                    np.sum(~(peaks_with_1) & peaks_with_2),\n",
    "                    np.sum(peaks_with_1 & peaks_with_2)\n",
    "                ]\n",
    "            ])\n",
    "            pval = scipy.stats.fisher_exact(\n",
    "                cont_table, alternative=\"greater\"\n",
    "            )[1]\n",
    "            pvals[i, j] = pval\n",
    "            pvals[j, i] = pval\n",
    "\n",
    "        # Self-co-occurrence: Poissonize balls in bins\n",
    "        # Expected number of collisions (via linearity of expectations):\n",
    "        num_hits = np.sum(peak_hit_indicators[:, i])  # number of \"balls\"\n",
    "        expected_collisions = num_hits * (num_hits - 1) / (2 * num_peaks)\n",
    "        num_collisions = np.sum(peak_hit_counts[:, i] >= 2)\n",
    "        pval = 1 - scipy.stats.poisson.cdf(num_collisions, mu=expected_collisions)\n",
    "        pvals[i, i] = pval\n",
    "    \n",
    "    return pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif_cooccurrence_heatmaps(count_matrix, pval_matrix, motif_keys):\n",
    "    \"\"\"\n",
    "    Plots a heatmap showing the number of peaks that have both types of\n",
    "    each motif, as well as a heatmap showing the p-value of co-occurrence.\n",
    "    \"\"\"\n",
    "    assert count_matrix.shape == pval_matrix.shape\n",
    "    num_motifs = pval_matrix.shape[0]\n",
    "    assert len(motif_keys) == num_motifs\n",
    "\n",
    "    # Cluster by p-value\n",
    "    inds = cluster_matrix_indices(pval_matrix, max(5, num_motifs // 4))\n",
    "    pval_matrix = pval_matrix[inds][:, inds]\n",
    "    count_matrix = count_matrix[inds][:, inds]\n",
    "    motif_keys = np.array(motif_keys)[inds]\n",
    "    \n",
    "    # Plot the p-value matrix\n",
    "\n",
    "    fig_width = max(5, num_motifs)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n",
    "    \n",
    "    # Replace 0s with minimum value (we'll label them properly later)\n",
    "    zero_mask = pval_matrix == 0\n",
    "    min_val = np.min(pval_matrix[~zero_mask])\n",
    "    pval_matrix[zero_mask] = min_val\n",
    "    logpval_matrix = -np.log10(pval_matrix)\n",
    "    \n",
    "    hmap = ax.imshow(logpval_matrix)\n",
    "\n",
    "    ax.set_xticks(np.arange(num_motifs))\n",
    "    ax.set_yticks(np.arange(num_motifs))\n",
    "    ax.set_xticklabels(motif_keys, rotation=45)\n",
    "    ax.set_yticklabels(motif_keys)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(num_motifs):\n",
    "        for j in range(num_motifs):\n",
    "            if zero_mask[i, j]:\n",
    "                text = \"Inf\"\n",
    "            else:\n",
    "                text = \"%.2f\" % np.abs(logpval_matrix[i, j])\n",
    "            ax.text(j, i, text, ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(hmap, orientation=\"horizontal\")\n",
    "\n",
    "    ax.set_title(\"-log(p) significance of peaks with both motifs\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the counts matrix\n",
    "\n",
    "    fig_width = max(5, num_motifs)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n",
    "    \n",
    "    hmap = ax.imshow(count_matrix)\n",
    "\n",
    "    ax.set_xticks(np.arange(num_motifs))\n",
    "    ax.set_yticks(np.arange(num_motifs))\n",
    "    ax.set_xticklabels(motif_keys, rotation=45)\n",
    "    ax.set_yticklabels(motif_keys)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(num_motifs):\n",
    "        for j in range(num_motifs):\n",
    "            ax.text(j, i, count_matrix[i, j], ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(hmap, orientation=\"horizontal\")\n",
    "\n",
    "    ax.set_title(\"Number of peaks with both motifs\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_violin_plot(ax, dist_list, colors):\n",
    "    \"\"\"\n",
    "    Creates a violin plot on the given instantiated axes.\n",
    "    `dist_list` is a list of vectors. `colors` is a parallel\n",
    "    list of colors for each violin.\n",
    "    \"\"\"\n",
    "    num_perfs = len(dist_list)\n",
    "\n",
    "    q1, med, q3 = np.stack([\n",
    "        np.nanpercentile(data, [25, 50, 70], axis=0) for data in dist_list\n",
    "    ], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    lower_outlier = q1 - (1.5 * iqr)\n",
    "    upper_outlier = q3 + (1.5 * iqr)\n",
    "\n",
    "\n",
    "    sorted_clipped_data = [  # Remove outliers based on outlier rule\n",
    "        np.sort(vec[(vec >= lower_outlier[i]) & (vec <= upper_outlier[i])])\n",
    "        for i, vec in enumerate(dist_list)\n",
    "    ]\n",
    "\n",
    "    plot_parts = ax.violinplot(\n",
    "        sorted_clipped_data, showmeans=False, showmedians=False, showextrema=False\n",
    "    )\n",
    "    violin_parts = plot_parts[\"bodies\"]\n",
    "    for i in range(num_perfs):\n",
    "        violin_parts[i].set_facecolor(colors[i])\n",
    "        violin_parts[i].set_edgecolor(colors[i])\n",
    "        violin_parts[i].set_alpha(0.7)\n",
    "\n",
    "    inds = np.arange(1, num_perfs + 1)\n",
    "    ax.vlines(inds, q1, q3, color=\"black\", linewidth=5, zorder=1)\n",
    "    ax.scatter(inds, med, marker=\"o\", color=\"white\", s=30, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intermotif_distance_violins(peak_hits, motif_keys, pair_inds):\n",
    "    \"\"\"\n",
    "    For each pair of motifs, plots a violin of distances beween\n",
    "    motifs. \n",
    "    \"\"\"\n",
    "    # First, compute the distribution of distances for each pair\n",
    "    distances = []\n",
    "    for i, j in tqdm.notebook.tqdm(pair_inds):\n",
    "        dists = []\n",
    "        for k in range(len(peak_hits)):\n",
    "            hits = peak_hits[k]\n",
    "\n",
    "            hits_1 = hits[hits[\"key\"] == motif_keys[i]]\n",
    "            hits_2 = hits[hits[\"key\"] == motif_keys[j]]\n",
    "\n",
    "            if hits_1.empty or hits_2.empty:\n",
    "                continue\n",
    "\n",
    "            pos_1 = np.array(hits_1[\"start\"])\n",
    "            pos_2 = np.array(hits_2[\"start\"])\n",
    "\n",
    "            len_1 = (hits_1[\"end\"] - hits_1[\"start\"]).values[0]\n",
    "            len_2 = (hits_2[\"end\"] - hits_2[\"start\"]).values[0]\n",
    "\n",
    "            # Differences beteween all pairs of positions\n",
    "            diffs = pos_2[None] - pos_1[:, None]\n",
    "            # Take minimum distance for each instance of motif 2, but only\n",
    "            # if the distance is an appropriate length\n",
    "            for row in diffs:\n",
    "                row = row[row != 0]\n",
    "                if not row.size:\n",
    "                    continue\n",
    "                dist = row[np.argmin(np.abs(row))]\n",
    "                if (dist < 0 and dist < -len_2) or (dist > 0 and dist > len_1):\n",
    "                    dists.append(dist)\n",
    "        dists = np.array(dists)\n",
    "        if not dists.size:\n",
    "            continue\n",
    "        distances.append(np.abs(dists))  # Take absolute value of distance\n",
    "    \n",
    "    if not distances:\n",
    "        print(\"No significantly co-occurring motifs\")\n",
    "        return\n",
    "    \n",
    "    # Plot the violins\n",
    "    fig, ax = plt.subplots(figsize=(int(1.7 * len(pair_inds)), 8))\n",
    "    create_violin_plot(ax, distances, [\"mediumorchid\"] * len(pair_inds))\n",
    "    ax.set_title(\"Distance distributions between motif instances\")\n",
    "    ax.set_xticks(np.arange(1, len(pair_inds) + 1))\n",
    "    ax.set_xticklabels([\"%s/%s\" % (motif_keys[i], motif_keys[j]) for i, j in pair_inds], rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import hit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PFMs\n",
    "pfms = import_tfmodisco_motifs(tfm_results_path)\n",
    "motif_keys = list(pfms.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import peaks\n",
    "peak_table = util.import_peak_table(peak_bed_paths)\n",
    "\n",
    "# Expand to input length\n",
    "peak_table[\"peak_start\"] = \\\n",
    "    (peak_table[\"peak_start\"] + peak_table[\"summit_offset\"]) - (input_length // 2)\n",
    "peak_table[\"peak_end\"] = peak_table[\"peak_start\"] + input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DeepSHAP scores\n",
    "hyp_scores, act_scores, one_hot_seqs, shap_coords = util.import_shap_scores(\n",
    "    shap_scores_path, hyp_score_key, center_cut_size=None, remove_non_acgt=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MOODS; import results if they already exist\n",
    "hits_path = os.path.join(moods_dir, \"moods_filtered_collapsed_scored.bed\")\n",
    "if os.path.exists(hits_path) and os.stat(hits_path).st_size:\n",
    "    hit_table = moods.import_moods_hits(hits_path)\n",
    "else:\n",
    "    hit_table = moods.get_moods_hits(\n",
    "        pfms, reference_fasta, peak_bed_paths[0], shap_scores_path,\n",
    "        expand_peak_length=input_length, temp_dir=moods_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter motif hit table by p-value using FDR estimation\n",
    "hit_table_filtered = filter_peak_hits_by_fdr(hit_table, fdr_cutoff=motif_fdr_cutoff)\n",
    "# Save the results back to MOODS directory\n",
    "filtered_hits_path = os.path.join(moods_dir, \"moods_filtered_collapsed_scored_thresholded.bed\")\n",
    "hit_table_filtered.to_csv(filtered_hits_path, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match peaks to motif hits\n",
    "peak_hits = get_peak_hits(peak_table, hit_table_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct count array of peaks and hits\n",
    "peak_hit_counts = get_peak_motif_counts(peak_hits, motif_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct count matrix of motif co-occurrence\n",
    "motif_cooccurrence_count_matrix = get_motif_cooccurrence_count_matrix(peak_hit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the matrix of p-values for motif co-occurrence\n",
    "motif_cooccurrence_pval_matrix = compute_cooccurrence_pvals(peak_hit_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"peaks-with-hits\"></a>\n",
    "### Proportion of peaks with hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_per_peak = np.array([len(hits) for hits in peak_hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vdomh.p(\"Number of peaks: %d\" % len(peak_table)))\n",
    "display(vdomh.p(\"Number of motif hits before FDR filtering: %d\" % len(hit_table)))\n",
    "display(vdomh.p(\"Number of motif hits after FDR filtering: %d\" % len(hit_table_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vdomh.p(\"Number of peaks with 0 motif hits: %d\" % np.sum(motifs_per_peak == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = [0, 0.25, 0.50, 0.75, 0.99, 1]\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Quantile\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Number of hits/peak\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "body = vdomh.tbody(*([\n",
    "    vdomh.tr(\n",
    "        vdomh.td(\"%.1f%%\" % (q * 100)), vdomh.td(\"%d\" % v)\n",
    "    ) for q, v in zip(quants, np.quantile(motifs_per_peak, quants))\n",
    "]))\n",
    "vdomh.table(header, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "bins = np.concatenate([np.arange(np.max(motifs_per_peak) + 1), [np.inf]])\n",
    "ax.hist(motifs_per_peak, bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "ax.set_title(\"Cumulative distribution of number of motif hits per peak\")\n",
    "ax.set_xlabel(\"Number of motifs k in peak\")\n",
    "ax.set_ylabel(\"Proportion of peaks with at least k motifs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_peaks_with_motif = np.sum(peak_hit_counts > 0, axis=0) / len(peak_hit_counts)\n",
    "labels = np.array(motif_keys)\n",
    "sorted_inds = np.flip(np.argsort(frac_peaks_with_motif))\n",
    "frac_peaks_with_motif = frac_peaks_with_motif[sorted_inds]\n",
    "labels = labels[sorted_inds]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.bar(np.arange(len(labels)), frac_peaks_with_motif)\n",
    "ax.set_title(\"Proportion of peaks with each motif\")\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"example-hits\"></a>\n",
    "### Examples of motif hits in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show some examples of sequences with motif hits\n",
    "num_to_draw = 3\n",
    "unique_counts = np.sort(np.unique(motifs_per_peak))\n",
    "motif_nums = []\n",
    "if 0 in motifs_per_peak:\n",
    "    motif_nums.append(0)\n",
    "if 1 in motifs_per_peak:\n",
    "    motif_nums.append(1)\n",
    "motif_nums.extend([\n",
    "    unique_counts[0],  # Minimum\n",
    "    unique_counts[len(unique_counts) // 2],  # Median\n",
    "    unique_counts[-1],  # Maximum\n",
    "])\n",
    "\n",
    "for motif_num in np.sort(np.unique(motif_nums)):\n",
    "    display(vdomh.h4(\"Sequences with %d motif hits\" % motif_num))\n",
    "    \n",
    "    peak_inds = np.where(motifs_per_peak == motif_num)[0]\n",
    "    table_rows = []\n",
    "    for i in np.random.choice(\n",
    "        peak_inds, size=min(num_to_draw, len(peak_inds)), replace=False\n",
    "    ):\n",
    "        peak_coord = peak_table.iloc[i][[\"chrom\", \"peak_start\", \"peak_end\"]].values\n",
    "        motif_hits = peak_hits[i]\n",
    "        \n",
    "        chrom, peak_start, peak_end = peak_coord\n",
    "        peak_len = peak_end - peak_start\n",
    "        mask = (shap_coords[:, 0] == chrom) & (shap_coords[:, 1] <= peak_start) & (shap_coords[:, 2] >= peak_end)\n",
    "        if not np.sum(mask):\n",
    "            fig = \"No matching input sequence found\"\n",
    "            table_rows.append(\n",
    "                vdomh.tr(\n",
    "                    vdomh.td(\"%s:%d-%d\" % (chrom, peak_start, peak_end)),\n",
    "                    vdomh.td(fig)\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "            \n",
    "        seq_index = np.where(mask)[0][0]  # Pick one\n",
    "        imp_scores = act_scores[seq_index]\n",
    "        _, seq_start, seq_end = shap_coords[seq_index]\n",
    "        \n",
    "        highlights = []\n",
    "        for _, row in motif_hits.iterrows():\n",
    "            start = row[\"start\"] - peak_start\n",
    "            end = start + (row[\"end\"] - row[\"start\"])\n",
    "            highlights.append((start, end))\n",
    "        \n",
    "        # Remove highlights that overrun the sequence\n",
    "        highlights = [(a, b) for a, b in highlights if a >= 0 and b < peak_len]\n",
    "        \n",
    "        start = peak_start - seq_start \n",
    "        end = start + peak_len\n",
    "        imp_scores_peak = imp_scores[start:end]\n",
    "        \n",
    "        fig = viz_sequence.plot_weights(\n",
    "            imp_scores_peak, subticks_frequency=(len(imp_scores_peak) + 1),\n",
    "            highlight={\"red\" : [pair for pair in highlights]},\n",
    "            return_fig=True\n",
    "        )\n",
    "        fig = util.figure_to_vdom_image(fig)\n",
    "        \n",
    "        table_rows.append(\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"%s:%d-%d\" % (chrom, peak_start, peak_end)),\n",
    "                vdomh.td(fig)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    table = vdomh.table(*table_rows)\n",
    "    display(table)\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"density\"></a>\n",
    "### Homotypic motif densities\n",
    "For each motif, show how many the motif occurs in each peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_homotypic_densities(peak_hit_counts, motif_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"co-occurrence\"></a>\n",
    "### Co-occurrence of motifs\n",
    "Proportion of time that motifs co-occur with each other in peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_peak_motif_indicator_heatmap(peak_hit_counts, motif_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_motif_cooccurrence_heatmaps(motif_cooccurrence_count_matrix, motif_cooccurrence_pval_matrix, motif_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"distance\"></a>\n",
    "### Distribution of distances between motifs\n",
    "When motifs co-occur, show the distance between the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get which pairs of motifs are significant\n",
    "# pvals, sig_pairs = [], []\n",
    "# for i in range(len(motif_keys)):\n",
    "#     for j in range(i + 1):\n",
    "#         if motif_cooccurrence_pval_matrix[i, j] < 1e-6:\n",
    "#             sig_pairs.append((i, j))\n",
    "#             pvals.append(motif_cooccurrence_pval_matrix[i, j])\n",
    "# inds = np.argsort(pvals)\n",
    "# sig_pairs = [sig_pairs[i] for i in inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermotif_distance_violins(peak_hits, motif_keys, sig_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
