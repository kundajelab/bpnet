{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[Profile metrics](#profile)\n",
    "\n",
    "[Count metrics](#count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import os\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "metrics_dir = os.environ[\"TFM_METRICS_DIR\"]\n",
    "preds_path = os.environ[\"TFM_PRED_PATH\"]\n",
    "   \n",
    "print(\"Performance metrics directory: %s\" % metrics_dir)\n",
    "print(\"Predictions path: %s\" % preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "test_chroms = [\"chr1\"]  # Set to None or empty list for all chromosomes\n",
    "\n",
    "metric_keys = [\n",
    "    \"mnll\", \"jsd\", \"cross_entropy\", \"pearson\", \"spearman\", \"mse\",\n",
    "    \"counts_pearson\", \"counts_spearman\"\n",
    "]\n",
    "\n",
    "metric_names = {\n",
    "    \"mnll\": \"normalized MNLL\",\n",
    "    \"jsd\": \"normalized JSD\",\n",
    "    \"cross_entropy\": \"normalized cross entropy\",\n",
    "    \"pearson\": \"Pearson correlation\",\n",
    "    \"spearman\": \"Spearman correlation\",\n",
    "    \"mse\": \"MSE\",\n",
    "    \"counts_pearson\": \"Pearson correlation\",\n",
    "    \"counts_spearman\": \"Spearman correlation\"\n",
    "}\n",
    "\n",
    "strands = [\"minus\", \"plus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For extracting metrics values, plotting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_performance_metrics(metrics_dir):\n",
    "    \"\"\"\n",
    "    Extracts the set of performance metrics from the directory of saved metrics.\n",
    "    Strands are pooled\n",
    "    Returns a dictionary of the following form:\n",
    "        `mnll`: <MNLL vector over peaks/strands>\n",
    "        `counts_pearson`: [\n",
    "            <MSE scalar for negative strand>\n",
    "            <MSE scalar for positive strand>\n",
    "        ]\n",
    "        ...\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    for key in metric_keys:\n",
    "        vecs = []\n",
    "        for strand in strands:\n",
    "            path = os.path.join(metrics_dir, \"task0_\" + strand, key + \".npz\")\n",
    "            reader = np.load(path)\n",
    "            vecs.append(reader[key])\n",
    "            \n",
    "        if key.startswith(\"counts_\"):\n",
    "            result[key] = np.array(vecs)\n",
    "        else:\n",
    "            result[key] = np.concatenate(vecs)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_true_pred_log_counts(preds_path, chrom_set=None):\n",
    "    \"\"\"\n",
    "    Imports the true and predicted log counts as two N x 2 arrays.\n",
    "    \"\"\"\n",
    "    with h5py.File(preds_path, \"r\") as f:\n",
    "        chroms = f[\"coords\"][\"coords_chrom\"][:].astype(str)\n",
    "        if chrom_set:\n",
    "            subset_inds = np.sort(np.where(np.isin(chroms, chrom_set))[0])\n",
    "        else:\n",
    "            subset_inds = np.arange(len(chroms))\n",
    "                        \n",
    "        true_log_counts = np.log(f[\"predictions\"][\"true_counts\"][subset_inds] + 1)\n",
    "        pred_log_counts = f[\"predictions\"][\"log_pred_counts\"][subset_inds]\n",
    "    return true_log_counts[:, 0], pred_log_counts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_image(ax, extent, direction=0, cmap_range=(0, 1), **kwargs):\n",
    "    \"\"\"\n",
    "    Adapted from\n",
    "    https://matplotlib.org/3.2.1/gallery/lines_bars_and_markers/gradient_bar.html\n",
    "    \"\"\"\n",
    "    phi = np.abs(direction) * np.pi / 2\n",
    "    v = np.array([np.cos(phi), np.sin(phi)])\n",
    "    X = np.array([[v @ [1, 0], v @ [1, 1]],\n",
    "                  [v @ [0, 0], v @ [0, 1]]])\n",
    "    a, b = cmap_range\n",
    "    X = a + (b - a) / X.max() * X\n",
    "    if direction < 0:\n",
    "        X = np.flip(X)\n",
    "    im = ax.imshow(X, extent=extent, interpolation='bicubic',\n",
    "                   vmin=0, vmax=1, **kwargs)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import performance metrics/bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics\n",
    "metrics = extract_performance_metrics(metrics_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import true/predicted log counts\n",
    "true_log_counts, pred_log_counts = import_true_pred_log_counts(preds_path, chrom_set=test_chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the sizes are the same\n",
    "num_peaks = len(true_log_counts)\n",
    "for key in metric_keys:\n",
    "    if key.startswith(\"counts_\"):\n",
    "        assert np.shape(metrics[key]) == (len(strands),)\n",
    "    else:\n",
    "        assert np.shape(metrics[key]) == (num_peaks * len(strands),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"profile\"></a>\n",
    "### Profile metrics\n",
    "Shown as CDFs of min-max-normalized values. Strands are pooled. Note that a MNLL, cross entropy, JSD, and MSE are best when minimized. Pearson and Spearman correlation are best when maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in metric_keys:\n",
    "    if key.startswith(\"counts_\"):\n",
    "        continue\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    if key in (\"pearson\", \"spearman\"):\n",
    "        gradient_image(\n",
    "            ax, direction=1, extent=(0, 1, 0, 1), transform=ax.transAxes,\n",
    "            cmap=\"RdYlGn\", cmap_range=(0, 1), alpha=0.2\n",
    "        )\n",
    "        bins = np.concatenate([[-np.inf], np.linspace(0, 1, num=100)])\n",
    "        ax.hist(metrics[key], bins=bins, density=True, histtype=\"step\", cumulative=-1)\n",
    "        ax.set_title(\"Inverse CDF of %s\" % metric_names[key])\n",
    "    else:\n",
    "        gradient_image(\n",
    "            ax, direction=-1, extent=(0, 1, 0, 1), transform=ax.transAxes,\n",
    "            cmap=\"RdYlGn\", cmap_range=(0, 1), alpha=0.2\n",
    "        )\n",
    "        bins = np.concatenate([np.linspace(0, 1, num=100), [np.inf]])\n",
    "        ax.hist(metrics[key], bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "        ax.set_title(\"CDF of %s\" % metric_names[key])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"count\"></a>\n",
    "### Count metrics\n",
    "Shown as scatter plots (strands pooled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(np.ravel(true_log_counts), np.ravel(pred_log_counts), alpha=0.03)\n",
    "ax.set_xlabel(\"True log counts\")\n",
    "ax.set_ylabel(\"Predicted log counts\")\n",
    "(min_x, max_x), (min_y, max_y) = ax.get_xlim(), ax.get_ylim()\n",
    "min_both, max_both = min(min_x, min_y), max(max_x, max_y)\n",
    "ax.set_xlim(min_both, max_both)\n",
    "ax.set_ylim(min_both, max_both)\n",
    "ax.plot(\n",
    "    [min_both, max_both], [min_both, max_both],\n",
    "    color=\"black\", linestyle=\"--\", alpha=0.3, zorder=0\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations(vec_1, vec_2):\n",
    "    finite_mask = np.isfinite(vec_1) & np.isfinite(vec_2)\n",
    "    vec_1 = vec_1[finite_mask]\n",
    "    vec_2 = vec_2[finite_mask]\n",
    "    return scipy.stats.pearsonr(vec_1, vec_2)[0], scipy.stats.spearmanr(vec_1, vec_2)[0]\n",
    "\n",
    "pool_p, pool_s = get_correlations(np.ravel(true_log_counts), np.ravel(pred_log_counts))\n",
    "pos_p, pos_s = get_correlations(true_log_counts[:, 0], pred_log_counts[:, 0])\n",
    "neg_p, neg_s = get_correlations(true_log_counts[:, 1], pred_log_counts[:, 1])\n",
    "avg_p, avg_s = np.mean([pos_p, neg_p]), np.mean([pos_s, neg_s])\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(),\n",
    "        vdomh.th(\"Pearson correlation\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Spearman correlation\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "body = vdomh.tbody(\n",
    "    vdomh.tr(\n",
    "        vdomh.td(\"Strands pooled\"), vdomh.td(str(pool_p)), vdomh.td(str(pool_s))\n",
    "    ),\n",
    "    vdomh.tr(\n",
    "        vdomh.td(\"Positive strand\"), vdomh.td(str(pos_p)), vdomh.td(str(pos_s))\n",
    "    ),\n",
    "    vdomh.tr(\n",
    "        vdomh.td(\"Negative strand\"), vdomh.td(str(neg_p)), vdomh.td(str(neg_s))\n",
    "    ),\n",
    "    vdomh.tr(\n",
    "        vdomh.td(\"Strands averaged\"), vdomh.td(str(avg_p)), vdomh.td(str(avg_s))\n",
    "    )\n",
    ")\n",
    "vdomh.table(header, body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
