{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[TF-MoDISco results](#tfm-results)\n",
    "\n",
    "[Summary of motifs](#motif-summary)\n",
    "\n",
    "[TOMTOM matches to motifs](#tomtom)\n",
    "\n",
    "[Sample of seqlets for each motif](#seqlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import util\n",
    "from tomtom import match_motifs_to_database\n",
    "import viz_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.cluster\n",
    "import scipy.cluster.hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "preds_path = os.environ[\"TFM_PRED_PATH\"]\n",
    "shap_scores_path = os.environ[\"TFM_SHAP_PATH\"]\n",
    "tfm_results_path = os.environ[\"TFM_TFM_PATH\"]\n",
    "peak_bed_paths = [os.environ[\"TFM_PEAKS_PATH\"]]\n",
    "tomtom_database_path = os.environ[\"TFM_TOMTOM_DB_PATH\"]\n",
    "tomtom_tmp_dir=os.environ[\"TFM_TOMTOM_TEMP_DIR\"]\n",
    "\n",
    "print(\"Predictions path: %s\" % preds_path)\n",
    "print(\"DeepSHAP scores path: %s\" % shap_scores_path)\n",
    "print(\"TF-MoDISco results path: %s\" % tfm_results_path)\n",
    "print(\"Peaks path: %s\" % peak_bed_paths[0])\n",
    "print(\"TOMTOM database path: %s\" % tomtom_database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "input_length, profile_length = 2114, 1000\n",
    "shap_score_center_size = 400\n",
    "profile_display_center_size = 400\n",
    "hyp_score_key = \"hyp_scores\"\n",
    "task_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profiles_and_coords(\n",
    "    seqlets_arr, one_hot_seqs, hyp_scores, true_profs, pred_profs, pred_coords,\n",
    "    input_length, profile_length, input_center_cut_size, profile_center_cut_size,\n",
    "    task_index=None\n",
    "):\n",
    "    \"\"\"\n",
    "    From the seqlets object of a TF-MoDISco pattern's seqlets and alignments,\n",
    "    extracts the predicted and observed profiles of the model, as well as the\n",
    "    set of coordinates for the seqlets.\n",
    "    Arguments:\n",
    "        `seqlets_arr`: a TF-MoDISco pattern's seqlets object array (N-array)\n",
    "        `one_hot_seqs`: an N x R x 4 array of input sequences, where R is\n",
    "            the cut centered size\n",
    "        `hyp_scores`: an N x R x 4 array of hypothetical importance scores\n",
    "        `true_profs`: an N x T x O x 2 array of true profile counts\n",
    "        `pred_profs`: an N x T x O x 2 array of predicted profile probabilities\n",
    "        `pred_coords`: an N x 3 object array of coordinates for the input sequence\n",
    "            underlying the predictions\n",
    "        `input_length`: length of original input sequences, I\n",
    "        `profile_length`: length of profile predictions, O\n",
    "        `input_center_cut_size`: centered cut size of SHAP scores used\n",
    "        `profile_center_cut_size`: size to cut profiles to when returning them, P\n",
    "        `task_index`: index of task to focus on for profiles; if None, returns\n",
    "            profiles for all tasks\n",
    "    Returns an N x (T or 1) x P x 2 array of true profile counts, an\n",
    "    N x (T or 1) x P x 2 array of predicted profile probabilities, an N x Q x 4\n",
    "    array of one-hot seqlet sequences, an N x Q x 4 array of hypothetical seqlet\n",
    "    importance scores, and an N x 3 object array of seqlet coordinates, where P\n",
    "    is the profile cut size and Q is the seqlet length. Returned profiles are\n",
    "    centered at the same center as the seqlets.\n",
    "    Note that it is important that the seqlet indices match exactly with the indices\n",
    "    out of the N. This should be the exact sequences in the original SHAP scores.\n",
    "    \"\"\"\n",
    "    true_seqlet_profs, pred_seqlet_profs, seqlet_seqs, seqlet_hyps, seqlet_coords = [], [], [], [], []\n",
    "    \n",
    "    def seqlet_coord_to_profile_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2) - ((input_length - profile_length) // 2)\n",
    "    \n",
    "    def seqlet_coord_to_input_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2)\n",
    "        \n",
    "    # For each seqlet, fetch the true/predicted profiles\n",
    "    for seqlet in seqlets_arr:\n",
    "        coord_index = seqlet.coor.example_idx\n",
    "        seqlet_start = seqlet.coor.start\n",
    "        seqlet_end = seqlet.coor.end\n",
    "        seqlet_rc = seqlet.coor.is_revcomp\n",
    "        \n",
    "        # Get indices of profile to cut out\n",
    "        seqlet_center = (seqlet_start + seqlet_end) // 2\n",
    "        prof_center = seqlet_coord_to_profile_coord(seqlet_center)\n",
    "        prof_start = prof_center - (profile_center_cut_size // 2)\n",
    "        prof_end = prof_start + profile_center_cut_size\n",
    "        \n",
    "        if task_index is None or true_profs.shape[1] == 1:\n",
    "            # Use all tasks if the predictions only have 1 task to begin with\n",
    "            task_start, task_end = None, None\n",
    "        else:\n",
    "            task_start, task_end = task_index, task_index + 1\n",
    "            \n",
    "        true_prof = true_profs[coord_index, task_start:task_end, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        pred_prof = pred_profs[coord_index, task_start:task_end, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        \n",
    "        true_seqlet_profs.append(true_prof)\n",
    "        pred_seqlet_profs.append(pred_prof)\n",
    "        \n",
    "        # The one-hot-sequences and hypothetical scores are assumed to already by cut/centered,\n",
    "        # so the indices match the seqlet indices\n",
    "        if seqlet_rc:\n",
    "            seqlet_seqs.append(np.flip(one_hot_seqs[coord_index, seqlet_start:seqlet_end], axis=(0, 1)))\n",
    "            seqlet_hyps.append(np.flip(hyp_scores[coord_index, seqlet_start:seqlet_end], axis=(0, 1)))\n",
    "        else:\n",
    "            seqlet_seqs.append(one_hot_seqs[coord_index, seqlet_start:seqlet_end])\n",
    "            seqlet_hyps.append(hyp_scores[coord_index, seqlet_start:seqlet_end])\n",
    "            \n",
    "        # Get the coordinates of the seqlet based on the input coordinates\n",
    "        inp_start = seqlet_coord_to_input_coord(seqlet_start)\n",
    "        inp_end = seqlet_coord_to_input_coord(seqlet_end)\n",
    "        chrom, start, _ = pred_coords[coord_index]\n",
    "        seqlet_coords.append([chrom, start + inp_start, start + inp_end])\n",
    "    \n",
    "    return np.stack(true_seqlet_profs), np.stack(pred_seqlet_profs), np.stack(seqlet_seqs), np.stack(seqlet_hyps), np.array(seqlet_coords, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(seqlet_true_profs, seqlet_pred_profs, kmeans_clusters=5):\n",
    "    \"\"\"\n",
    "    Plots the given profiles with a heatmap.\n",
    "    Arguments:\n",
    "        `seqlet_true_profs`: an N x O x 2 NumPy array of true profiles, either as raw\n",
    "            counts or probabilities (they will be normalized)\n",
    "        `seqlet_pred_profs`: an N x O x 2 NumPy array of predicted profiles, either as\n",
    "            raw counts or probabilities (they will be normalized)\n",
    "        `kmeans_cluster`: when displaying profile heatmaps, there will be this\n",
    "            many clusters\n",
    "    \"\"\"\n",
    "    assert len(seqlet_true_profs.shape) == 3\n",
    "    assert seqlet_true_profs.shape == seqlet_pred_profs.shape\n",
    "    num_profs, width, _ = seqlet_true_profs.shape\n",
    "\n",
    "    # First, normalize the profiles along the output profile dimension\n",
    "    def normalize(arr, axis=0):\n",
    "        arr_sum = np.sum(arr, axis=axis, keepdims=True)\n",
    "        arr_sum[arr_sum == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return arr / arr_sum\n",
    "    true_profs_norm = normalize(seqlet_true_profs, axis=1)\n",
    "    pred_profs_norm = normalize(seqlet_pred_profs, axis=1)\n",
    "\n",
    "    # Compute the mean profiles across all examples\n",
    "    true_profs_mean = np.mean(true_profs_norm, axis=0)\n",
    "    pred_profs_mean = np.mean(pred_profs_norm, axis=0)\n",
    "\n",
    "    # Perform k-means clustering on the predicted profiles, with the strands pooled\n",
    "    kmeans_clusters = max(5, num_profs // 50)  # Set number of clusters based on number of profiles, with minimum\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=kmeans_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(\n",
    "        np.reshape(pred_profs_norm, (pred_profs_norm.shape[0], -1))\n",
    "    )\n",
    "\n",
    "    # Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "            scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Order the profiles so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "\n",
    "    # Compute a matrix of profiles, normalized to the maximum height, ordered by clusters\n",
    "    def make_profile_matrix(flat_profs, order_inds):\n",
    "        matrix = flat_profs[order_inds]\n",
    "        maxes = np.max(matrix, axis=1, keepdims=True)\n",
    "        maxes[maxes == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return matrix / maxes\n",
    "    true_matrix = make_profile_matrix(true_profs_norm, cluster_inds)\n",
    "    pred_matrix = make_profile_matrix(pred_profs_norm, cluster_inds)\n",
    "\n",
    "    # Create a figure with the right dimensions\n",
    "    mean_height = 4\n",
    "    heatmap_height = min(num_profs * 0.004, 8)\n",
    "    fig_height = mean_height + (2 * heatmap_height)\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 2, figsize=(16, fig_height), sharex=True,\n",
    "        gridspec_kw={\n",
    "            \"width_ratios\": [1, 1],\n",
    "            \"height_ratios\": [mean_height / fig_height, heatmap_height / fig_height, heatmap_height / fig_height]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Plot the average predictions\n",
    "    ax[0, 0].plot(true_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 0].plot(-true_profs_mean[:, 1], color=\"darkorange\")\n",
    "    ax[0, 1].plot(pred_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 1].plot(-pred_profs_mean[:, 1], color=\"darkorange\")\n",
    "\n",
    "    # Set axes on average predictions\n",
    "    max_mean_val = max(np.max(true_profs_mean), np.max(pred_profs_mean))\n",
    "    mean_ylim = max_mean_val * 1.05  # Make 5% higher\n",
    "    ax[0, 0].set_title(\"True profiles\")\n",
    "    ax[0, 0].set_ylabel(\"Average probability\")\n",
    "    ax[0, 1].set_title(\"Predicted profiles\")\n",
    "    for j in (0, 1):\n",
    "        ax[0, j].set_ylim(-mean_ylim, mean_ylim)\n",
    "        ax[0, j].label_outer()\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    ax[1, 0].imshow(true_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[1, 1].imshow(pred_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[2, 0].imshow(true_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "    ax[2, 1].imshow(pred_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "\n",
    "    # Set axes on heatmaps\n",
    "    for i in (1, 2):\n",
    "        for j in (0, 1):\n",
    "            ax[i, j].set_yticks([])\n",
    "            ax[i, j].set_yticklabels([])\n",
    "            ax[i, j].label_outer()\n",
    "    width = true_matrix.shape[1]\n",
    "    delta = 100\n",
    "    num_deltas = (width // 2) // delta\n",
    "    labels = list(range(max(-width // 2, -num_deltas * delta), min(width // 2, num_deltas * delta) + 1, delta))\n",
    "    tick_locs = [label + max(width // 2, num_deltas * delta) for label in labels]\n",
    "    for j in (0, 1):\n",
    "        ax[2, j].set_xticks(tick_locs)\n",
    "        ax[2, j].set_xticklabels(labels)\n",
    "        ax[2, j].set_xlabel(\"Distance from peak summit (bp)\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summit_distances(coords, peak_table):\n",
    "    \"\"\"\n",
    "    Given a set of coordinates, computes the distance of the center of each\n",
    "    coordinate to the nearest summit.\n",
    "    Arguments:\n",
    "        `coords`: an N x 3 object array of coordinates\n",
    "        `peak_table`: a 6-column table of peak data, as imported by\n",
    "            `import_peak_table`\n",
    "    Returns and N-array of integers, which is the distance of each coordinate\n",
    "    midpoint to the nearest coordinate.\n",
    "    \"\"\"\n",
    "    chroms = coords[:, 0]\n",
    "    midpoints = (coords[:, 1] + coords[:, 2]) // 2\n",
    "    dists = []\n",
    "    for i in range(len(coords)):\n",
    "        chrom = chroms[i]\n",
    "        midpoint = midpoints[i]\n",
    "        rows = peak_table[peak_table[\"chrom\"] == chrom]\n",
    "        dist_arr = (midpoint - rows[\"summit\"]).values\n",
    "        min_dist = dist_arr[np.argmin(np.abs(dist_arr))]\n",
    "        dists.append(min_dist)\n",
    "    return np.array(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summit_dists(summit_dists):\n",
    "    \"\"\"\n",
    "    Plots the distribution of seqlet distances to summits.\n",
    "    Arguments:\n",
    "        `summit_dists`: the array of distances as returned by\n",
    "            `get_summit_distances`\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    num_bins = max(len(summit_dists) // 30, 20)\n",
    "    plt.hist(summit_dists, bins=num_bins, color=\"purple\")\n",
    "    plt.title(\"Histogram of distance of seqlets to peak summits\")\n",
    "    plt.xlabel(\"Signed distance from seqlet center to nearest peak summit (bp)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SHAP scores, profile predictions, and TF-MoDISco results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SHAP coordinates and one-hot sequences\n",
    "hyp_scores, _, one_hot_seqs, shap_coords = util.import_shap_scores(shap_scores_path, hyp_score_key, center_cut_size=shap_score_center_size, remove_non_acgt=False)\n",
    "# This cuts the sequences/scores off just as how TF-MoDISco saw them, but the coordinates are uncut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the set of all profiles and their coordinates\n",
    "true_profs, pred_profs, all_pred_coords = util.import_profiles(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the set of peaks\n",
    "peak_table = util.import_peak_table(peak_bed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the predicted profiles/coordinates to the task-specific SHAP coordinates/scores\n",
    "shap_coords_table = pd.DataFrame(shap_coords, columns=[\"chrom\", \"start\", \"end\"])\n",
    "pred_coords_table = pd.DataFrame(all_pred_coords, columns=[\"chrom\", \"start\", \"end\"])\n",
    "\n",
    "subset_inds = pred_coords_table.reset_index().drop_duplicates([\"chrom\", \"start\", \"end\"]).merge(\n",
    "    shap_coords_table.reset_index(), on=[\"chrom\", \"start\", \"end\"]\n",
    ").sort_values(\"index_y\")[\"index_x\"].values\n",
    "\n",
    "true_profs = true_profs[subset_inds]\n",
    "pred_profs = pred_profs[subset_inds]\n",
    "pred_coords = all_pred_coords[subset_inds]\n",
    "\n",
    "# Make sure the coordinates all match\n",
    "assert np.all(pred_coords == shap_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TF-MoDISco results object\n",
    "tfm_obj = util.import_tfmodisco_results(tfm_results_path, hyp_scores, one_hot_seqs, shap_score_center_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some SHAP score tracks\n",
    "Plot the central region of some randomly selected actual importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.random.choice(hyp_scores.shape[0], size=5, replace=False):\n",
    "    viz_sequence.plot_weights((hyp_scores[index] * one_hot_seqs[index])[100:300], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tfm-results\"></a>\n",
    "## Plot TF-MoDISco results\n",
    "Plot all motifs by metacluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_pfms, motif_hcwms, motif_cwms = [], [], []  # Save the trimmed PFMs, hCWMs, and CWMs\n",
    "motif_pfms_short = []  # PFMs that are even more trimmed (for TOMTOM)\n",
    "num_seqlets = []  # Number of seqlets for each motif\n",
    "motif_seqlets = []  # Save seqlets of each motif\n",
    "metaclusters = tfm_obj.metacluster_idx_to_submetacluster_results\n",
    "num_metaclusters = len(metaclusters.keys())\n",
    "for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "    metacluster = metaclusters[metacluster_key]\n",
    "    display(vdomh.h3(\"Metacluster %d/%d\" % (metacluster_i + 1, num_metaclusters)))\n",
    "    patterns = metacluster.seqlets_to_patterns_result.patterns\n",
    "    if not patterns:\n",
    "        break\n",
    "    motif_pfms.append([])\n",
    "    motif_hcwms.append([])\n",
    "    motif_cwms.append([])\n",
    "    motif_pfms_short.append([])\n",
    "    num_seqlets.append([])\n",
    "    motif_seqlets.append([])\n",
    "    num_patterns = len(patterns)\n",
    "    for pattern_i, pattern in enumerate(patterns):\n",
    "        seqlets = pattern.seqlets\n",
    "        display(vdomh.h4(\"Pattern %d/%d\" % (pattern_i + 1, num_patterns)))\n",
    "        display(vdomh.p(\"%d seqlets\" % len(seqlets)))\n",
    "        \n",
    "        pfm = pattern[\"sequence\"].fwd\n",
    "        hcwm = pattern[\"task0_hypothetical_contribs\"].fwd\n",
    "        cwm = pattern[\"task0_contrib_scores\"].fwd\n",
    "        \n",
    "        pfm_fig = viz_sequence.plot_weights(pfm, subticks_frequency=10, return_fig=True)\n",
    "        hcwm_fig = viz_sequence.plot_weights(hcwm, subticks_frequency=10, return_fig=True)\n",
    "        cwm_fig = viz_sequence.plot_weights(cwm, subticks_frequency=10, return_fig=True)\n",
    "        pfm_fig.tight_layout()\n",
    "        hcwm_fig.tight_layout()\n",
    "        cwm_fig.tight_layout()\n",
    "        \n",
    "        motif_table = vdomh.table(\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Sequence (PFM)\"),\n",
    "                vdomh.td(util.figure_to_vdom_image(pfm_fig))\n",
    "            ),\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Hypothetical contributions (hCWM)\"),\n",
    "                vdomh.td(util.figure_to_vdom_image(hcwm_fig))\n",
    "            ),\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Actual contributions (CWM)\"),\n",
    "                vdomh.td(util.figure_to_vdom_image(cwm_fig))\n",
    "            )\n",
    "        )\n",
    "        display(motif_table)\n",
    "        plt.close(\"all\")  # Remove all standing figures\n",
    "        \n",
    "        # Trim short version of PFM (for TOMTOM)\n",
    "        short_trimmed_pfm = util.trim_motif(pfm, pfm)\n",
    "        motif_pfms_short[-1].append(short_trimmed_pfm)\n",
    "        \n",
    "        # Trim long versions of motifs (for display)\n",
    "        trimmed_pfm = util.trim_motif(pfm, pfm, pad=4)\n",
    "        trimmed_hcwm = util.trim_motif(pfm, hcwm, pad=4)\n",
    "        trimmed_cwm = util.trim_motif(pfm, cwm, pad=4)\n",
    "        \n",
    "        motif_pfms[-1].append(trimmed_pfm)\n",
    "        motif_hcwms[-1].append(trimmed_hcwm)\n",
    "        motif_cwms[-1].append(trimmed_cwm)\n",
    "        \n",
    "        num_seqlets[-1].append(len(seqlets))\n",
    "        \n",
    "        seqlet_true_profs, seqlet_pred_profs, seqlet_seqs, seqlet_hyps, seqlet_coords = extract_profiles_and_coords(\n",
    "            seqlets, one_hot_seqs, hyp_scores, true_profs, pred_profs, pred_coords,\n",
    "            input_length, profile_length, shap_score_center_size,\n",
    "            profile_display_center_size, task_index=task_index\n",
    "        )\n",
    "        \n",
    "        motif_seqlets[-1].append((seqlet_seqs, seqlet_hyps))\n",
    "\n",
    "        assert np.allclose(np.sum(seqlet_seqs, axis=0) / len(seqlet_seqs), pattern[\"sequence\"].fwd)\n",
    "        # ^Sanity check: PFM derived from seqlets match the PFM stored in the pattern\n",
    "        plot_profiles(\n",
    "            # Flatten to NT x O x 2\n",
    "            np.reshape(seqlet_true_profs, (-1, seqlet_true_profs.shape[2], seqlet_true_profs.shape[3])),\n",
    "            np.reshape(seqlet_pred_profs, (-1, seqlet_pred_profs.shape[2], seqlet_pred_profs.shape[3]))\n",
    "        )\n",
    "        \n",
    "        summit_dists = get_summit_distances(seqlet_coords, peak_table)\n",
    "        plot_summit_dists(summit_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"motif-summary\"></a>\n",
    "## Summary of motifs\n",
    "\n",
    "Motifs are trimmed based on information content, and presented in descending order by number of supporting seqlets. The motifs are separated by metacluster. The motifs are presented as hCWMs. The forward orientation is defined as the orientation that is richer in purines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"45%\"}),\n",
    "    vdomh.col(style={\"width\": \"45%\"})\n",
    ")\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"#\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Seqlets\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Forward\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Reverse\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "for i in range(len(motif_hcwms)):\n",
    "    display(vdomh.h3(\"Metacluster %d/%d\" % (i + 1, num_metaclusters)))\n",
    "    body = []\n",
    "    for j in range(len(motif_hcwms[i])):\n",
    "        motif = motif_hcwms[i][j]\n",
    "        if np.sum(motif[:, [0, 2]]) > 0.5 * np.sum(motif):\n",
    "            # Forward is purine-rich, reverse-complement is pyrimidine-rich\n",
    "            f, rc = motif, np.flip(motif, axis=(0, 1))\n",
    "        else:\n",
    "            f, rc = np.flip(motif, axis=(0, 1)), motif\n",
    "            \n",
    "        f_fig = viz_sequence.plot_weights(f, figsize=(20, 4), return_fig=True)\n",
    "        f_fig.tight_layout()\n",
    "        rc_fig = viz_sequence.plot_weights(rc, figsize=(20, 4), return_fig=True)\n",
    "        rc_fig.tight_layout()\n",
    "\n",
    "        body.append(\n",
    "            vdomh.tr(\n",
    "                vdomh.td(str(j + 1)),\n",
    "                vdomh.td(str(num_seqlets[i][j])),\n",
    "                vdomh.td(util.figure_to_vdom_image(f_fig)),\n",
    "                vdomh.td(util.figure_to_vdom_image(rc_fig))\n",
    "            )\n",
    "        )\n",
    "    display(vdomh.table(colgroup, header, vdomh.tbody(*body)))\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tomtom\"></a>\n",
    "## Top TOMTOM matches for each motif\n",
    "\n",
    "Here, the TF-MoDISco motifs are plotted as hCWMs, but the TOMTOM matches are shown as PWMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches_to_keep = 10\n",
    "num_matches_to_show = 5\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Motif ID\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"q-val\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"PWM\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "for i in range(len(motif_pfms)):\n",
    "    display(vdomh.h3(\"Metacluster %d/%d\" % (i + 1, num_metaclusters)))\n",
    "    \n",
    "    # Compute TOMTOM matches for all motifs in the metacluster at once\n",
    "    tomtom_matches = match_motifs_to_database(\n",
    "        motif_pfms_short[i], top_k=num_matches_to_keep,\n",
    "        database_path=tomtom_database_path, temp_dir=tomtom_tmp_dir\n",
    "    )\n",
    "    \n",
    "    for j in range(len(motif_pfms[i])):\n",
    "        display(vdomh.h4(\"Motif %d/%d\" % (j + 1, len(motif_pfms[i]))))\n",
    "        viz_sequence.plot_weights(motif_hcwms[i][j])\n",
    "    \n",
    "        body = []\n",
    "        for k, (match_name, match_pfm, match_qval) in enumerate(tomtom_matches[j]):\n",
    "            fig = viz_sequence.plot_weights(util.pfm_to_pwm(match_pfm), return_fig=True)\n",
    "            fig.tight_layout()\n",
    "            if k < num_matches_to_show:\n",
    "                body.append(\n",
    "                    vdomh.tr(\n",
    "                        vdomh.td(match_name),\n",
    "                        vdomh.td(str(match_qval)),\n",
    "                        vdomh.td(util.figure_to_vdom_image(fig))\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                body.append(\n",
    "                    vdomh.tr(\n",
    "                        vdomh.td(match_name),\n",
    "                        vdomh.td(str(match_qval)),\n",
    "                        vdomh.td(\"Not shown\")\n",
    "                    )\n",
    "                )\n",
    "        if not body:\n",
    "            display(vdomh.p(\"No TOMTOM matches passing threshold\"))\n",
    "        else:\n",
    "            display(vdomh.table(header, vdomh.tbody(*body)))\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seqlets\"></a>\n",
    "## Sample of seqlets supporting each motif\n",
    "Here, the motifs are presented as hCWMs, along with the actual importance scores of a random sample of seqlets that support the motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seqlets_to_show = 10\n",
    "\n",
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"50%\"}),\n",
    "    vdomh.col(style={\"width\": \"50%\"})\n",
    ")\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Motif hCWM\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Seqlets\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "for i in range(len(motif_hcwms)):\n",
    "    display(vdomh.h3(\"Metacluster %d/%d\" % (i + 1, num_metaclusters)))\n",
    "    \n",
    "    for j in range(len(motif_hcwms[i])):\n",
    "        display(vdomh.h4(\"Motif %d/%d\" % (j + 1, len(motif_hcwms[i]))))\n",
    "        \n",
    "        motif_fig = viz_sequence.plot_weights(motif_hcwms[i][j], figsize=(20, 4), return_fig=True)\n",
    "        motif_fig.tight_layout()\n",
    "        \n",
    "        seqlet_seqs, seqlet_hyps = motif_seqlets[i][j]\n",
    "        \n",
    "        sample_size = min(num_seqlets_to_show, len(seqlet_seqs))\n",
    "        sample_inds = np.random.choice(len(seqlet_seqs), size=sample_size, replace=False)\n",
    "        sample = []\n",
    "        for k in sample_inds:\n",
    "            fig = viz_sequence.plot_weights(seqlet_hyps[k] * seqlet_seqs[k], subticks_frequency=10, return_fig=True)\n",
    "            fig.tight_layout()\n",
    "            sample.append(util.figure_to_vdom_image(fig))\n",
    "        body = vdomh.tbody(vdomh.tr(vdomh.td(util.figure_to_vdom_image(motif_fig)), vdomh.td(*sample)))\n",
    "        display(vdomh.table(colgroup, header, body))\n",
    "        plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
